{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9cdfd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib as mpl\n",
    "from collections import OrderedDict\n",
    "sys.path.append('../.')\n",
    "\n",
    "# Import only what's actually needed to avoid the dask import issue\n",
    "from GrindingData import GrindingData\n",
    "from MyDataset import project_dir\n",
    "from MyModels import GrindingPredictor\n",
    "from GrindingData import GrindingData\n",
    "from MyDataset import project_dir, allowed_input_types, get_dataset, get_collate_fn\n",
    "device = 'cpu'\n",
    "CHECKPOINT_DIR = os.path.join(\"../lfs\",\"checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73c744c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds=10\n",
    "repeat=10\n",
    "for _input_type in allowed_input_types[:-1]:\n",
    "    for i in range(int(folds*repeat)):\n",
    "        checkpoint_path = f\"{_input_type}_fold{i}_of_folds{folds}.pt\"\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_path)\n",
    "# _input_type = allowed_input_types[0]\n",
    "_input_type = 'all'\n",
    "_input_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "867981d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required components: {'all'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds=10\n",
    "repeat=10\n",
    "checkpoint_path = f\"{_input_type}_fold{0}_of_folds{folds}.pt\"\n",
    "checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_path)\n",
    "\n",
    "dataset = get_dataset(input_type=_input_type)\n",
    "collate_fn = get_collate_fn(input_type=_input_type)\n",
    "loader = DataLoader(dataset, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "model = GrindingPredictor(input_type=_input_type, interp=False)\n",
    "model.to(device)\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "_state_dict = checkpoint['model_state']\n",
    "model.load_state_dict(_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f3cbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required components: {'ae_spec'}\n",
      "Required components: {'vib_spec'}\n",
      "Required components: {'ae_features'}\n",
      "Required components: {'vib_features'}\n",
      "Required components: {'ae_spec', 'ae_features'}\n",
      "Required components: {'vib_spec', 'vib_features'}\n",
      "Required components: {'vib_spec', 'ae_spec', 'ae_features', 'vib_features'}\n",
      "Required components: {'pp', 'ae_features'}\n",
      "Required components: {'pp', 'vib_features'}\n",
      "Required components: {'pp'}\n",
      "Required components: {'vib_spec', 'ae_spec'}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../lfs/checkpoints/ae_spec+vib_spec_fold0_of_folds10.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m model = GrindingPredictor(input_type=_input_type, interp=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     12\u001b[39m model.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m checkpoint = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m _state_dict = checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     15\u001b[39m model.load_state_dict(_state_dict, strict=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/serialization.py:1484\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1482\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1486\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1487\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1489\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../lfs/checkpoints/ae_spec+vib_spec_fold0_of_folds10.pt'"
     ]
    }
   ],
   "source": [
    "folds=10\n",
    "repeat=10\n",
    "for _input_type in allowed_input_types[:-1]:\n",
    "    for i in range(int(folds*repeat))[:1]:\n",
    "        checkpoint_path = f\"{_input_type}_fold{i}_of_folds{folds}.pt\"\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_path)\n",
    "\n",
    "        dataset = get_dataset(input_type=_input_type)\n",
    "        collate_fn = get_collate_fn(input_type=_input_type)\n",
    "        loader = DataLoader(dataset, batch_size=3, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "        model = GrindingPredictor(input_type=_input_type, interp=False)\n",
    "        model.to(device)\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        _state_dict = checkpoint['model_state']\n",
    "        model.load_state_dict(_state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26829e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GrindingPredictor:\n\tsize mismatch for regressor.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([128, 192]).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m      3\u001b[39m _state_dict = checkpoint[\u001b[33m'\u001b[39m\u001b[33mmodel_state\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# _state_dict = OrderedDict()\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# for old_key, value in old_state_dict.items():\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m#     new_key = old_key\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     _state_dict[new_key] = value\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ai/lib/python3.12/site-packages/torch/nn/modules/module.py:2624\u001b[39m, in \u001b[36mModule.load_state_dict\u001b[39m\u001b[34m(self, state_dict, strict, assign)\u001b[39m\n\u001b[32m   2616\u001b[39m         error_msgs.insert(\n\u001b[32m   2617\u001b[39m             \u001b[32m0\u001b[39m,\n\u001b[32m   2618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2619\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[32m   2620\u001b[39m             ),\n\u001b[32m   2621\u001b[39m         )\n\u001b[32m   2623\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2624\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   2625\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   2626\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m\"\u001b[39m.join(error_msgs)\n\u001b[32m   2627\u001b[39m         )\n\u001b[32m   2628\u001b[39m     )\n\u001b[32m   2629\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[31mRuntimeError\u001b[39m: Error(s) in loading state_dict for GrindingPredictor:\n\tsize mismatch for regressor.0.weight: copying a param with shape torch.Size([128, 64]) from checkpoint, the shape in current model is torch.Size([128, 192])."
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "_state_dict = checkpoint['model_state']\n",
    "model.load_state_dict(_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7c97ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[34.3949],\n",
       "         [33.2866],\n",
       "         [33.1813]], grad_fn=<AddmmBackward0>),\n",
       " tensor([112, 112, 105]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "inputs = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "labels = batch['label'].to(device)\n",
    "pred = model.forward(inputs)\n",
    "pred, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b6aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c91997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[34.3949],\n",
       "         [33.2866],\n",
       "         [33.1813]], grad_fn=<AddmmBackward0>),\n",
       " tensor([112, 112, 105]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27cec85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('ae_spec_processor.conv.0.weight',\n",
       "              tensor([[[[ 1.8810e-01,  9.7475e-02, -4.0856e-02],\n",
       "                        [ 2.0492e-01,  1.7017e-01,  1.7988e-02],\n",
       "                        [ 4.0255e-02, -1.3628e-01, -3.5494e-01]],\n",
       "              \n",
       "                       [[-1.0835e-01,  7.8401e-02,  8.1748e-02],\n",
       "                        [ 9.1444e-02, -8.1134e-02, -1.8812e-01],\n",
       "                        [-1.9436e-01,  4.1149e-02, -1.1562e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.6569e-01,  1.3392e-01, -1.8564e-01],\n",
       "                        [-5.6104e-02, -1.9228e-01,  1.2668e-01],\n",
       "                        [ 2.2337e-01, -7.4634e-02, -1.5330e-01]],\n",
       "              \n",
       "                       [[-1.3344e-01, -2.6960e-01, -1.5580e-01],\n",
       "                        [ 3.0235e-01, -1.5618e-01,  1.6963e-01],\n",
       "                        [-2.3885e-01, -1.2401e-02,  2.3923e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1516e-01,  1.0318e-01, -1.0890e-01],\n",
       "                        [-1.3158e-01, -8.0487e-02,  3.8901e-01],\n",
       "                        [-2.4442e-01, -5.5597e-03,  5.9254e-02]],\n",
       "              \n",
       "                       [[ 5.2065e-03,  4.0577e-02,  1.0621e-01],\n",
       "                        [-3.1454e-01, -2.9740e-02,  7.6678e-02],\n",
       "                        [ 6.7758e-02,  1.2994e-01,  2.1784e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0092e-02,  1.9510e-01, -2.3788e-01],\n",
       "                        [ 8.5625e-02, -2.4304e-01, -5.0391e-02],\n",
       "                        [ 2.8585e-01,  1.5982e-01, -1.7534e-01]],\n",
       "              \n",
       "                       [[ 4.8087e-02,  4.9749e-02, -2.8734e-02],\n",
       "                        [-2.7995e-02, -8.3231e-02, -5.6376e-02],\n",
       "                        [-1.3865e-01,  7.9509e-02,  2.3488e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.0016e-02, -1.0038e-01, -1.1049e-01],\n",
       "                        [ 1.9177e-03,  6.4439e-02, -6.5315e-03],\n",
       "                        [ 1.5595e-01, -2.7357e-02, -1.8371e-01]],\n",
       "              \n",
       "                       [[-1.7903e-01,  8.8397e-03,  1.5328e-01],\n",
       "                        [ 3.3643e-01,  2.0526e-01,  5.9570e-02],\n",
       "                        [-8.4947e-02,  5.3939e-02, -1.9910e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1779e-01, -2.3260e-01,  6.5153e-04],\n",
       "                        [ 1.2297e-01,  1.4854e-01,  2.5280e-03],\n",
       "                        [-1.8079e-01, -7.9856e-02,  2.7987e-01]],\n",
       "              \n",
       "                       [[-1.6105e-01, -2.6613e-01, -4.2213e-01],\n",
       "                        [-1.4429e-01, -1.4780e-02, -1.2426e-01],\n",
       "                        [-3.7327e-01,  2.3600e-01,  1.1078e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5889e-01, -6.9026e-02, -1.8991e-01],\n",
       "                        [ 9.2117e-02,  9.5977e-02, -6.1932e-02],\n",
       "                        [ 7.4485e-02, -6.9984e-03,  9.3914e-02]],\n",
       "              \n",
       "                       [[ 7.9947e-02,  3.6577e-03, -6.4262e-02],\n",
       "                        [-1.1500e-01, -7.0432e-03,  1.6623e-01],\n",
       "                        [-7.0488e-03,  1.2122e-01,  5.4241e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5108e-01, -2.1527e-01, -1.2338e-01],\n",
       "                        [ 2.4898e-02,  4.2753e-02, -3.1596e-01],\n",
       "                        [-2.5345e-01,  9.8927e-03, -3.1914e-02]],\n",
       "              \n",
       "                       [[-6.4775e-02, -3.0085e-02, -2.1349e-01],\n",
       "                        [-3.0222e-02,  9.6849e-05, -2.4824e-01],\n",
       "                        [-3.0941e-02, -6.5113e-02, -1.6082e-01]]]])),\n",
       "             ('ae_spec_processor.conv.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('ae_spec_processor.conv.4.weight',\n",
       "              tensor([[ 0.0961, -0.1644,  0.1330,  ..., -0.1455, -0.0850,  0.1789],\n",
       "                      [-0.0305,  0.0319, -0.1228,  ...,  0.0311, -0.1256,  0.0282],\n",
       "                      [-0.0593, -0.1495,  0.1707,  ..., -0.0872,  0.0658, -0.1369],\n",
       "                      ...,\n",
       "                      [ 0.0710, -0.1028, -0.0980,  ...,  0.0557,  0.1386,  0.0540],\n",
       "                      [-0.1808,  0.1535,  0.1101,  ...,  0.1829, -0.1135, -0.0334],\n",
       "                      [-0.1071,  0.0693, -0.1138,  ..., -0.1926, -0.0837, -0.0485]])),\n",
       "             ('ae_spec_processor.conv.4.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('vib_spec_processor.conv.0.weight',\n",
       "              tensor([[[[ 1.4406e-01,  8.7198e-02,  1.1621e-01],\n",
       "                        [ 1.1486e-01,  1.5890e-01,  1.2260e-01],\n",
       "                        [ 8.3647e-02, -2.9863e-01,  2.3130e-01]],\n",
       "              \n",
       "                       [[-1.3700e-01,  3.6483e-01,  1.9614e-01],\n",
       "                        [ 1.4566e-01,  1.9861e-01, -5.5094e-02],\n",
       "                        [ 1.3688e-01, -6.8096e-02, -1.0030e-01]],\n",
       "              \n",
       "                       [[ 2.4242e-02, -1.5599e-01,  1.4805e-01],\n",
       "                        [ 8.7519e-02, -2.3110e-01, -1.1364e-01],\n",
       "                        [ 3.0058e-01, -1.3413e-01, -2.3635e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.6066e-02,  3.1256e-02, -1.2028e-01],\n",
       "                        [ 1.5196e-01, -9.6100e-02,  4.4310e-01],\n",
       "                        [-2.1405e-01, -4.7953e-02,  2.7373e-01]],\n",
       "              \n",
       "                       [[ 6.8010e-02, -2.2637e-04,  4.5280e-02],\n",
       "                        [ 8.8399e-02, -5.5120e-02, -4.6207e-01],\n",
       "                        [-1.5244e-01,  6.0233e-03, -1.3794e-01]],\n",
       "              \n",
       "                       [[ 3.1078e-01, -2.1133e-02,  5.3429e-02],\n",
       "                        [ 1.9682e-02, -2.2586e-01, -4.0242e-02],\n",
       "                        [-2.3979e-01,  1.7805e-01, -1.6901e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4969e-02,  9.2148e-02, -1.1670e-01],\n",
       "                        [-8.0935e-02,  2.4701e-01,  1.4667e-01],\n",
       "                        [ 1.0226e-01, -3.7600e-02,  9.7810e-02]],\n",
       "              \n",
       "                       [[ 1.9990e-01, -1.1975e-02, -1.2064e-01],\n",
       "                        [ 2.4732e-01,  1.2422e-01, -2.0462e-01],\n",
       "                        [ 6.2846e-02, -5.0186e-02, -5.7444e-01]],\n",
       "              \n",
       "                       [[ 1.4289e-01,  3.1107e-03, -3.5494e-01],\n",
       "                        [ 1.6687e-01, -9.1904e-02, -3.9094e-02],\n",
       "                        [-1.4092e-04, -1.7612e-01, -8.6214e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6867e-03, -4.0302e-02,  8.7468e-02],\n",
       "                        [-5.9072e-02, -1.1799e-01,  1.5214e-01],\n",
       "                        [-7.0403e-02,  1.1843e-01, -6.8552e-02]],\n",
       "              \n",
       "                       [[-5.0265e-01,  1.5326e-01, -2.3705e-01],\n",
       "                        [ 2.1169e-01,  2.4737e-03,  1.4100e-01],\n",
       "                        [ 1.7488e-01,  1.4958e-01, -2.9303e-01]],\n",
       "              \n",
       "                       [[-1.9364e-01,  1.8416e-01,  1.2502e-01],\n",
       "                        [ 4.0366e-01,  5.6693e-02,  2.0018e-02],\n",
       "                        [-1.1295e-02,  1.1813e-01, -3.2515e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.2008e-02,  1.5052e-01,  5.6095e-02],\n",
       "                        [ 1.5776e-01,  5.0126e-02, -4.4335e-01],\n",
       "                        [-3.5476e-01, -9.8404e-02, -4.1085e-02]],\n",
       "              \n",
       "                       [[ 1.0311e-01, -3.7274e-02, -1.0730e-01],\n",
       "                        [-4.2454e-02,  2.7131e-01,  1.1615e-01],\n",
       "                        [ 4.9845e-01,  1.4481e-01,  9.1666e-02]],\n",
       "              \n",
       "                       [[ 2.5143e-01,  1.6014e-01, -2.9071e-01],\n",
       "                        [-8.8870e-02,  4.4256e-02, -8.4415e-02],\n",
       "                        [-3.9999e-01,  9.6978e-02,  1.4487e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.5056e-02,  1.2458e-01, -5.1353e-02],\n",
       "                        [ 3.5843e-01, -3.2176e-02, -1.2008e-01],\n",
       "                        [-1.3513e-01,  1.4087e-01,  2.3252e-01]],\n",
       "              \n",
       "                       [[ 3.0914e-01,  5.1135e-02, -1.5037e-01],\n",
       "                        [-1.2032e-02, -1.9754e-02, -3.2996e-01],\n",
       "                        [-1.3916e-01,  5.2730e-02,  1.8378e-01]],\n",
       "              \n",
       "                       [[-7.0873e-02, -2.0358e-01,  2.8764e-02],\n",
       "                        [-3.1811e-01,  1.9729e-01,  1.5816e-01],\n",
       "                        [-1.2291e-01,  2.5064e-02,  4.4190e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4482e-01, -8.7613e-02, -3.0972e-01],\n",
       "                        [ 1.4089e-01, -2.6742e-01,  8.9106e-02],\n",
       "                        [-2.4625e-01,  2.7691e-01,  1.6150e-01]],\n",
       "              \n",
       "                       [[ 1.3500e-01,  1.1574e-01,  1.4930e-01],\n",
       "                        [-2.0679e-01,  1.5317e-01, -7.1988e-03],\n",
       "                        [ 5.9205e-02,  2.3847e-01, -2.4468e-01]],\n",
       "              \n",
       "                       [[-2.1657e-01, -2.4701e-01, -1.0890e-02],\n",
       "                        [ 1.0193e-01,  1.6316e-01, -2.2686e-01],\n",
       "                        [-1.8544e-01, -4.1957e-02,  4.1973e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4057e-01,  4.4216e-02,  2.9402e-01],\n",
       "                        [ 4.4199e-02, -5.5321e-02,  1.0620e-01],\n",
       "                        [ 3.1553e-01, -1.9195e-01, -1.4541e-01]],\n",
       "              \n",
       "                       [[ 1.9359e-01,  5.1516e-02,  1.3226e-01],\n",
       "                        [ 1.2488e-02,  3.0849e-02,  5.8681e-02],\n",
       "                        [ 2.5798e-01, -1.1681e-01,  1.8399e-01]],\n",
       "              \n",
       "                       [[-3.4495e-02,  8.6974e-02,  3.0277e-01],\n",
       "                        [ 2.0622e-01,  2.1006e-01,  2.2267e-01],\n",
       "                        [-1.2841e-01,  1.6007e-01, -1.4284e-01]]]])),\n",
       "             ('vib_spec_processor.conv.0.bias',\n",
       "              tensor([-1.6861e-05,  7.8694e-03,  5.9917e-03,  1.7164e-03, -3.7613e-03,\n",
       "                      -1.7820e-05,  8.9371e-03, -4.8756e-06])),\n",
       "             ('vib_spec_processor.conv.4.weight',\n",
       "              tensor([[ 0.1333, -0.0382, -0.1276,  ..., -0.1658, -0.1597,  0.1416],\n",
       "                      [-0.1132,  0.1392, -0.0320,  ..., -0.1589, -0.1669,  0.1013],\n",
       "                      [ 0.1432, -0.1736, -0.1153,  ..., -0.0120, -0.0101,  0.1716],\n",
       "                      ...,\n",
       "                      [-0.1730,  0.1559,  0.1438,  ..., -0.0280, -0.1363,  0.1188],\n",
       "                      [ 0.1599, -0.1727, -0.0939,  ...,  0.0385, -0.0437, -0.0813],\n",
       "                      [-0.0536,  0.1645,  0.1775,  ...,  0.1393,  0.0828, -0.1436]])),\n",
       "             ('vib_spec_processor.conv.4.bias',\n",
       "              tensor([-0.0024,  0.0029, -0.0084, -0.0020,  0.0083, -0.0016,  0.0016, -0.0033,\n",
       "                      -0.0145,  0.0010, -0.0015,  0.0054,  0.0032, -0.0056, -0.0022, -0.0031,\n",
       "                       0.0009, -0.0023,  0.0006, -0.0033,  0.0117, -0.0032, -0.0094, -0.0022,\n",
       "                       0.0105,  0.0069,  0.0087,  0.0124, -0.0019, -0.0127, -0.0060, -0.0011])),\n",
       "             ('ae_interpreter.attention.0.weight',\n",
       "              tensor([[-0.1438,  0.0926, -0.1093,  ...,  0.1396, -0.1800, -0.1300],\n",
       "                      [ 0.1567,  0.0100,  0.0240,  ..., -0.0416,  0.2035, -0.0551],\n",
       "                      [ 0.0332, -0.0447, -0.1762,  ..., -0.1546, -0.1730, -0.1865],\n",
       "                      ...,\n",
       "                      [-0.1351, -0.0255, -0.1414,  ...,  0.0399, -0.0525,  0.2001],\n",
       "                      [-0.1179,  0.2134,  0.1726,  ..., -0.0286,  0.0831, -0.1446],\n",
       "                      [ 0.1410,  0.1010, -0.2339,  ...,  0.1228, -0.0966, -0.1176]])),\n",
       "             ('ae_interpreter.attention.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('ae_interpreter.attention.2.weight',\n",
       "              tensor([[-0.1520, -0.1325,  0.0242,  ...,  0.0617,  0.0995,  0.0753],\n",
       "                      [ 0.1423, -0.1732, -0.1215,  ...,  0.0842, -0.1243,  0.2257],\n",
       "                      [ 0.0289,  0.0481,  0.1252,  ..., -0.2420,  0.1394, -0.0976],\n",
       "                      ...,\n",
       "                      [ 0.0778, -0.1179,  0.0844,  ...,  0.0898, -0.0760, -0.1576],\n",
       "                      [-0.0403,  0.1515, -0.1771,  ...,  0.0522, -0.1158,  0.2106],\n",
       "                      [-0.1460, -0.0324, -0.0803,  ..., -0.1109, -0.2398, -0.0554]])),\n",
       "             ('ae_interpreter.attention.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('ae_interpreter.feature_processor.weight',\n",
       "              tensor([[-0.1043, -0.1385,  0.2225,  ..., -0.1045, -0.0481, -0.0367],\n",
       "                      [-0.1914,  0.2103,  0.2125,  ..., -0.0161, -0.1746,  0.1685],\n",
       "                      [-0.0404, -0.1047, -0.2074,  ..., -0.1234, -0.0523, -0.1980],\n",
       "                      ...,\n",
       "                      [-0.0453,  0.1253, -0.0068,  ..., -0.1774, -0.2049, -0.0113],\n",
       "                      [-0.1310, -0.0461,  0.0549,  ...,  0.1917, -0.0990,  0.0681],\n",
       "                      [ 0.1803, -0.1745, -0.1073,  ..., -0.2371,  0.0344,  0.0941]])),\n",
       "             ('ae_interpreter.feature_processor.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('vib_interpreter.attention.0.weight',\n",
       "              tensor([[-0.0239, -0.2057,  0.0472,  ..., -0.1251, -0.1912, -0.1621],\n",
       "                      [-0.1692,  0.1222, -0.1088,  ...,  0.1244, -0.0536,  0.0675],\n",
       "                      [-0.0073,  0.1869,  0.1514,  ...,  0.0545, -0.1260, -0.2345],\n",
       "                      ...,\n",
       "                      [ 0.1798, -0.0360, -0.1987,  ..., -0.0843,  0.1391, -0.2365],\n",
       "                      [ 0.2425,  0.0895,  0.2102,  ...,  0.0233,  0.1899,  0.0137],\n",
       "                      [-0.2337, -0.1774, -0.1005,  ...,  0.0366, -0.0274, -0.1053]])),\n",
       "             ('vib_interpreter.attention.0.bias',\n",
       "              tensor([ 8.5244e-03,  9.3375e-03,  7.7294e-05, -7.1878e-04,  1.0146e-02,\n",
       "                       3.5166e-03,  5.4215e-03, -1.1760e-02, -1.4408e-02,  2.9634e-07,\n",
       "                       6.7594e-03,  3.1555e-08, -1.6390e-05, -8.8689e-04,  6.7801e-05,\n",
       "                       7.8114e-03, -2.2555e-05, -1.7568e-02,  5.6695e-04, -8.1165e-06,\n",
       "                      -6.2813e-05, -5.3045e-03,  8.3206e-10,  1.2151e-02, -5.4451e-03,\n",
       "                       4.0555e-05,  9.1098e-03, -1.4925e-04,  1.0157e-02,  2.8393e-03,\n",
       "                       1.3946e-03,  1.4367e-02, -8.8862e-07, -1.2791e-02, -1.1735e-05,\n",
       "                      -1.0313e-02,  5.4056e-06,  2.3200e-03,  2.4135e-03, -4.7563e-04,\n",
       "                      -3.0579e-07,  1.4626e-02,  1.3428e-05,  9.0269e-03,  1.2329e-03,\n",
       "                      -3.7923e-06,  8.7034e-04, -9.5992e-03, -9.2251e-03, -9.3272e-04,\n",
       "                       1.9320e-05,  1.4884e-02,  9.4946e-03,  2.2670e-04, -5.2003e-03,\n",
       "                      -2.0438e-04, -6.0538e-06,  1.1544e-02, -4.2166e-03,  5.9732e-06,\n",
       "                      -1.9706e-02,  7.0902e-03, -2.9994e-03,  9.1934e-03])),\n",
       "             ('vib_interpreter.attention.2.weight',\n",
       "              tensor([[-0.0081,  0.1025, -0.1118,  ...,  0.1123, -0.1563, -0.1282],\n",
       "                      [ 0.2043,  0.1657, -0.2401,  ..., -0.2070,  0.1610,  0.2314],\n",
       "                      [ 0.2319,  0.0195, -0.1766,  ..., -0.1670,  0.0918,  0.1987],\n",
       "                      ...,\n",
       "                      [ 0.0660, -0.2047, -0.2049,  ...,  0.0723,  0.2397,  0.0761],\n",
       "                      [ 0.1846, -0.0559,  0.2134,  ...,  0.1149,  0.0735,  0.1703],\n",
       "                      [ 0.1750, -0.0113, -0.1082,  ...,  0.1722,  0.1423, -0.0913]])),\n",
       "             ('vib_interpreter.attention.2.bias',\n",
       "              tensor([-5.0148e-04, -1.5798e-03, -1.0354e-03, -4.6449e-04, -2.2357e-03,\n",
       "                      -5.2656e-04, -1.9313e-03, -8.5742e-04,  6.5155e-03, -1.9874e-05,\n",
       "                      -6.2167e-05, -1.5865e-04, -1.3197e-03, -2.1202e-03, -1.0153e-04,\n",
       "                      -2.2676e-04, -1.1149e-04, -1.5848e-03, -3.3816e-04, -1.1534e-04,\n",
       "                      -4.3989e-04, -8.1825e-04, -2.9417e-04, -2.0707e-03, -8.1538e-04,\n",
       "                      -3.2503e-04, -3.7416e-03, -3.5727e-04, -5.2451e-04,  6.1468e-03,\n",
       "                      -3.7124e-03,  2.7162e-04, -2.7845e-04, -1.1665e-03, -2.5103e-03,\n",
       "                      -1.1850e-03])),\n",
       "             ('vib_interpreter.feature_processor.weight',\n",
       "              tensor([[-0.0829,  0.1386, -0.2137,  ...,  0.1302, -0.1434,  0.1614],\n",
       "                      [-0.1885,  0.0814,  0.1223,  ...,  0.1660,  0.0234,  0.0424],\n",
       "                      [ 0.0172,  0.0818,  0.1473,  ..., -0.1757, -0.0321, -0.1228],\n",
       "                      ...,\n",
       "                      [ 0.1960, -0.2018, -0.0467,  ...,  0.0904,  0.1716, -0.1263],\n",
       "                      [-0.1765, -0.0369, -0.1297,  ...,  0.2042,  0.2368,  0.1111],\n",
       "                      [-0.1921,  0.2007, -0.0828,  ...,  0.2085, -0.2419, -0.1330]])),\n",
       "             ('vib_interpreter.feature_processor.bias',\n",
       "              tensor([-2.7657e-03, -4.8459e-03, -4.0676e-03,  3.4076e-03,  1.2088e-02,\n",
       "                       1.3889e-02,  4.6317e-03, -2.3890e-03, -3.9606e-05,  8.9165e-03,\n",
       "                      -1.2713e-03,  1.4215e-02,  1.3228e-02, -8.4067e-03,  1.1292e-03,\n",
       "                       7.2903e-03, -4.6082e-03, -7.0038e-04, -3.1580e-04,  3.1169e-03,\n",
       "                      -3.0166e-04,  3.9099e-04, -5.4845e-05,  1.4783e-03,  1.0096e-02,\n",
       "                       3.0321e-03,  6.9170e-03,  2.2018e-03,  5.7483e-03,  7.5787e-04,\n",
       "                      -2.7823e-03, -1.3635e-03,  1.7672e-05,  1.1096e-03, -1.9412e-03,\n",
       "                       1.9424e-04, -1.7060e-04, -3.9813e-03,  3.6102e-03, -8.1735e-03,\n",
       "                       7.8908e-03,  5.7104e-03,  1.6370e-03, -6.2544e-03,  8.3057e-03,\n",
       "                       1.5131e-03, -2.1549e-05, -5.7286e-03,  1.2507e-02,  1.2450e-04,\n",
       "                       8.7047e-05, -4.8621e-05, -2.4224e-03, -1.4295e-02, -1.7355e-03,\n",
       "                       1.1501e-03, -3.1342e-03, -6.8539e-04, -9.1738e-03,  7.4227e-03,\n",
       "                      -1.5330e-05,  1.1307e-02, -2.1279e-05, -1.5775e-05])),\n",
       "             ('pp_encoder.0.weight',\n",
       "              tensor([[ 1.8920e-01, -2.4353e-01, -2.6133e-02],\n",
       "                      [-2.9822e-01,  2.5239e-01,  2.9050e-01],\n",
       "                      [ 2.9759e-01,  1.0460e-01,  1.6731e-01],\n",
       "                      [-1.0444e-02, -1.6825e-01,  2.2022e-01],\n",
       "                      [-2.3130e-01, -2.6898e-01, -2.6244e-01],\n",
       "                      [-2.0739e-01, -1.8430e-01, -1.0723e-01],\n",
       "                      [ 9.5758e-02,  6.0333e-03,  1.4878e-01],\n",
       "                      [ 1.8311e-01, -2.0831e-01, -2.2868e-01],\n",
       "                      [-6.4132e-02,  2.6312e-01, -1.7428e-01],\n",
       "                      [ 1.9438e-01, -2.5702e-02, -2.1659e-02],\n",
       "                      [ 9.1093e-02, -1.0878e-02, -9.7989e-02],\n",
       "                      [-1.3611e-01, -2.2180e-01,  1.5697e-01],\n",
       "                      [-2.9639e-03,  2.2420e-01,  1.5313e-01],\n",
       "                      [ 2.5304e-01, -1.8382e-01,  2.3579e-01],\n",
       "                      [-1.9351e-01,  7.8129e-02, -2.1369e-01],\n",
       "                      [-2.5408e-01,  1.1894e-01,  2.5753e-01],\n",
       "                      [-1.2829e-01,  5.8431e-02, -1.6809e-01],\n",
       "                      [ 1.6058e-02, -6.9331e-02,  8.4590e-02],\n",
       "                      [ 2.3323e-01,  6.4668e-02,  1.7970e-01],\n",
       "                      [ 1.1086e-01,  1.5497e-01, -2.7280e-01],\n",
       "                      [ 6.5520e-02, -1.9150e-04, -2.8352e-01],\n",
       "                      [ 6.9524e-02,  1.9588e-03, -1.9674e-01],\n",
       "                      [ 2.6463e-01, -1.5662e-01, -9.1659e-02],\n",
       "                      [ 2.9016e-01, -1.8970e-01,  1.7078e-01],\n",
       "                      [-2.7678e-01,  2.1046e-01,  5.6297e-03],\n",
       "                      [ 2.5334e-01, -1.7370e-01,  1.8902e-01],\n",
       "                      [-2.7668e-01, -7.9895e-02,  1.6512e-01],\n",
       "                      [ 8.9660e-02,  2.8577e-01, -2.4421e-01],\n",
       "                      [ 3.0139e-02,  2.4688e-01, -2.8980e-01],\n",
       "                      [ 1.6917e-01, -7.0130e-02, -2.0080e-01],\n",
       "                      [-1.4064e-01, -2.7267e-01,  2.2614e-02],\n",
       "                      [ 1.2103e-01,  2.4028e-02, -2.6112e-01],\n",
       "                      [ 3.1137e-02,  2.9291e-01, -1.9525e-01],\n",
       "                      [-1.4188e-01,  1.8135e-01,  2.0784e-01],\n",
       "                      [-8.1498e-02, -1.2903e-01,  1.8752e-01],\n",
       "                      [ 9.3766e-03, -2.7297e-01,  9.0401e-02],\n",
       "                      [-8.8942e-02,  9.1153e-02, -1.9706e-02],\n",
       "                      [ 2.2753e-04, -1.2441e-01,  4.2713e-02],\n",
       "                      [-1.0894e-01,  6.0503e-02,  2.6299e-01],\n",
       "                      [ 6.5286e-02,  1.4558e-01, -1.6744e-01],\n",
       "                      [-2.2884e-01,  3.6365e-02, -1.0593e-01],\n",
       "                      [ 1.3219e-01, -2.6611e-01, -2.5876e-01],\n",
       "                      [-1.6465e-01,  1.8996e-01, -1.0457e-01],\n",
       "                      [ 4.7743e-02,  7.5969e-02,  2.2072e-01],\n",
       "                      [-4.9531e-02,  1.0807e-01, -1.8200e-01],\n",
       "                      [ 1.0126e-01,  5.3697e-02,  1.8409e-01],\n",
       "                      [-6.5660e-02,  1.6012e-01,  4.2331e-02],\n",
       "                      [-1.6869e-01, -1.7778e-02,  5.6791e-02],\n",
       "                      [ 1.0259e-01,  9.7563e-02, -5.7875e-02],\n",
       "                      [-1.3580e-02,  2.7715e-01,  9.0033e-02],\n",
       "                      [ 1.9134e-01, -1.5490e-01, -5.9805e-02],\n",
       "                      [-1.8480e-01, -1.2301e-01, -1.4368e-01],\n",
       "                      [ 9.0312e-02,  2.0999e-01,  2.4323e-02],\n",
       "                      [ 2.7480e-01, -1.7825e-01, -3.3638e-02],\n",
       "                      [-1.9462e-01, -2.8482e-01, -5.0851e-03],\n",
       "                      [ 2.0112e-01,  4.9365e-02, -2.5987e-01],\n",
       "                      [ 2.6560e-01,  1.5123e-01, -1.4074e-01],\n",
       "                      [-6.4792e-02, -7.7204e-02, -1.1170e-01],\n",
       "                      [-2.4434e-01,  2.1770e-01, -7.2574e-02],\n",
       "                      [-2.4591e-01, -7.8471e-02,  2.4328e-01],\n",
       "                      [-1.3484e-01, -2.0584e-01, -2.0051e-01],\n",
       "                      [ 2.4841e-01, -2.4676e-01,  6.3619e-02],\n",
       "                      [ 1.5355e-01,  5.6369e-02,  1.9582e-01],\n",
       "                      [ 2.2573e-01, -1.6651e-01,  1.6198e-01]])),\n",
       "             ('pp_encoder.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('pp_encoder.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('pp_encoder.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('regressor.0.weight',\n",
       "              tensor([[ 0.0285,  0.1337, -0.0213,  ...,  0.0109,  0.0691,  0.0085],\n",
       "                      [ 0.1374, -0.0879,  0.1170,  ...,  0.0381,  0.1299,  0.0946],\n",
       "                      [ 0.0340,  0.0630, -0.1100,  ..., -0.0812,  0.0733,  0.0870],\n",
       "                      ...,\n",
       "                      [-0.0350,  0.0227, -0.0442,  ...,  0.1497, -0.0991,  0.0175],\n",
       "                      [-0.1072,  0.0666,  0.0467,  ...,  0.0640, -0.0275,  0.0777],\n",
       "                      [ 0.0824, -0.1179,  0.0718,  ...,  0.1657, -0.0247, -0.0911]])),\n",
       "             ('regressor.0.bias',\n",
       "              tensor([-8.6482e-03,  1.2083e-02, -1.2577e-02,  5.9030e-04,  9.6521e-03,\n",
       "                       7.1556e-03, -1.8116e-38,  4.9493e-03,  1.6704e-03, -7.5960e-03,\n",
       "                       2.6714e-03, -8.9329e-03,  1.1385e-02,  1.3489e-02, -1.5385e-04,\n",
       "                       4.2839e-03,  5.2444e-05,  1.2070e-02, -4.1457e-03,  6.0543e-03,\n",
       "                      -1.2393e-02, -7.4922e-23,  1.0116e-04,  6.2771e-03, -7.6737e-03,\n",
       "                      -2.0181e-03, -6.9752e-03,  8.0097e-03,  1.0205e-02, -6.1618e-05,\n",
       "                      -2.3098e-35, -9.6829e-05,  1.0444e-02,  0.0000e+00, -4.6479e-03,\n",
       "                      -9.7386e-04,  1.6217e-03,  8.5339e-03,  7.4157e-03, -5.0887e-03,\n",
       "                       1.1441e-02, -3.0235e-03,  1.2874e-02,  1.1090e-02,  9.4133e-03,\n",
       "                       4.7488e-03,  1.2113e-02,  7.6011e-03, -2.1404e-03,  1.8639e-04,\n",
       "                       5.6911e-03, -1.4137e-02, -1.2790e-02, -9.2263e-04, -2.9329e-03,\n",
       "                       2.4529e-03,  3.6503e-04, -2.7584e-05, -2.9693e-35,  7.5993e-05,\n",
       "                       3.1121e-05,  1.1502e-02,  9.9213e-05, -9.2239e-03, -2.0903e-03,\n",
       "                      -8.2248e-04,  4.5300e-03, -5.5495e-03,  6.7254e-03, -7.6320e-03,\n",
       "                       1.0404e-04,  4.6268e-05, -2.3296e-03, -3.4888e-03,  6.6786e-03,\n",
       "                      -2.1548e-35, -1.4617e-04, -6.3118e-03,  1.2669e-03,  8.8919e-03,\n",
       "                      -1.2572e-02, -2.5314e-14,  1.5785e-02, -7.1438e-03, -2.7546e-03,\n",
       "                      -5.1056e-03, -1.3412e-02,  1.1717e-02,  1.1089e-02, -6.6989e-03,\n",
       "                       7.1625e-03, -4.4946e-38,  9.3986e-03,  1.5003e-37,  4.8846e-33,\n",
       "                      -1.4540e-03, -1.8670e-04, -3.6694e-04, -9.9520e-04, -8.2707e-04,\n",
       "                       3.0208e-03,  0.0000e+00, -1.3497e-03, -5.7046e-03, -2.4235e-04,\n",
       "                      -2.3777e-03, -8.6137e-03, -1.3582e-02,  1.2650e-02, -5.5034e-03,\n",
       "                      -1.3716e-33,  5.7828e-03,  8.8211e-07, -3.1487e-35, -1.1562e-03,\n",
       "                       4.4067e-04, -1.4834e-04,  8.1532e-03,  1.0060e-03,  5.0073e-03,\n",
       "                       2.0446e-03,  0.0000e+00, -2.6260e-03, -2.2602e-03,  4.1200e-03,\n",
       "                       2.5192e-03, -1.6940e-32,  0.0000e+00])),\n",
       "             ('regressor.2.weight',\n",
       "              tensor([[-0.0659,  0.2018, -0.1855,  0.0407,  0.0898,  0.1561, -0.1992,  0.0981,\n",
       "                        0.0456, -0.1720,  0.2069, -0.0458,  0.1812,  0.1935,  0.1184,  0.0806,\n",
       "                        0.0579,  0.1714, -0.0540,  0.1016, -0.1705, -0.0973, -0.0570,  0.1718,\n",
       "                       -0.2110, -0.0254, -0.1087,  0.1844,  0.1932, -0.0781, -0.0338, -0.0654,\n",
       "                        0.0989,  0.0203, -0.0605, -0.0576,  0.1060,  0.2018,  0.0740, -0.0213,\n",
       "                        0.0505, -0.1735,  0.1678,  0.1766,  0.1529,  0.1522,  0.1986,  0.1657,\n",
       "                       -0.1419, -0.0871,  0.0791, -0.1729, -0.0907, -0.0102, -0.0524,  0.0388,\n",
       "                        0.0793,  0.0376, -0.0396,  0.1195,  0.0405,  0.1533,  0.0073, -0.1509,\n",
       "                       -0.2115, -0.1788,  0.0365, -0.1130,  0.0537, -0.1274, -0.1987,  0.0455,\n",
       "                       -0.0038, -0.1136,  0.0695, -0.1879, -0.0791, -0.1034,  0.1807,  0.2083,\n",
       "                       -0.1284, -0.0336,  0.1423, -0.2009, -0.1670, -0.1354, -0.1469,  0.2075,\n",
       "                        0.1206, -0.1092,  0.1217,  0.0742,  0.1128, -0.0726, -0.1469, -0.1855,\n",
       "                       -0.0408, -0.1957, -0.0701, -0.0655,  0.0515,  0.1394, -0.0865, -0.0694,\n",
       "                       -0.0610, -0.1667, -0.0877, -0.1874,  0.1644, -0.0788, -0.0416,  0.0657,\n",
       "                        0.0458,  0.1553, -0.0206,  0.0106, -0.0097,  0.1507,  0.1250,  0.0835,\n",
       "                        0.0355,  0.0051, -0.0133, -0.0665,  0.0342,  0.1526,  0.0661,  0.1377]])),\n",
       "             ('regressor.2.bias', tensor([0.0072]))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint['model_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0518995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
